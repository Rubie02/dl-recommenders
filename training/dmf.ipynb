{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "connection_string = \"mongodb+srv://root:GiaMinh0802@cluster0.hrfrhsi.mongodb.net/HMart_v2?retryWrites=true&w=majority\"\n",
    "client = MongoClient(connection_string)\n",
    "db = client.HMart_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_rating = []\n",
    "ratings_col = db[\"ratings\"]\n",
    "ratings = ratings_col.find()\n",
    "\n",
    "for rating in ratings:\n",
    "    rating_format = {\n",
    "        \"user\": str(rating[\"user\"]),\n",
    "        \"product\": str(rating[\"product\"]),\n",
    "        \"star\": str(rating[\"star\"])\n",
    "    }\n",
    "    list_rating.append(rating_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 150485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'user': '65e5fcec011337aa452eea8c',\n",
       "  'product': '65498a03ae75adf790aca093',\n",
       "  'star': '5'},\n",
       " {'user': '65e5fcec011337aa452eea8c',\n",
       "  'product': '65498839ae75adf790aca039',\n",
       "  'star': '4'},\n",
       " {'user': '65e5fcec011337aa452eea8c',\n",
       "  'product': '65490c4eb87aac9ca3dab26a',\n",
       "  'star': '4'},\n",
       " {'user': '65e5fcec011337aa452eea8c',\n",
       "  'product': '654a1512ae75adf790acc14b',\n",
       "  'star': '5'},\n",
       " {'user': '65e5fcec011337aa452eea8c',\n",
       "  'product': '654a2e9eae75adf790acc894',\n",
       "  'star': '5'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Size: \" + str(len(list_rating)))\n",
    "list_rating[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_rating = pd.DataFrame(list_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       user                   product star\n",
      "0  65e5fcec011337aa452eea8c  65498a03ae75adf790aca093    5\n",
      "1  65e5fcec011337aa452eea8c  65498839ae75adf790aca039    4\n",
      "2  65e5fcec011337aa452eea8c  65490c4eb87aac9ca3dab26a    4\n",
      "3  65e5fcec011337aa452eea8c  654a1512ae75adf790acc14b    5\n",
      "4  65e5fcec011337aa452eea8c  654a2e9eae75adf790acc894    5\n",
      "Number of unique users: 5001\n",
      "Number of products with at least one rating: 493\n",
      "Max rating: 5\n",
      "Min rating: 1\n"
     ]
    }
   ],
   "source": [
    "print(df_rating.head())\n",
    "print(f'Number of unique users: {df_rating[\"user\"].nunique()}')\n",
    "print(f'Number of products with at least one rating: {df_rating[\"product\"].nunique()}')\n",
    "print(f'Max rating: {df_rating[\"star\"].max()}')\n",
    "print(f'Min rating: {df_rating[\"star\"].min()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction matrix size: 2465493\n",
      "Interaction count: 150485\n",
      "Sparsity: 0.938964\n"
     ]
    }
   ],
   "source": [
    "interaction_matrix_size = df_rating[\"user\"].nunique() * df_rating[\"product\"].nunique()\n",
    "interaction_count = df_rating.shape[0]\n",
    "sparsity = 1 - (interaction_count / interaction_matrix_size)\n",
    "\n",
    "print(f'Interaction matrix size: {interaction_matrix_size}')\n",
    "print(f'Interaction count: {interaction_count}')\n",
    "print(f'Sparsity: {sparsity:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Create a label encoder object\n",
    "le_user = LabelEncoder()\n",
    "le_product = LabelEncoder()\n",
    "\n",
    "# Convert the user_id and product_id columns into integers\n",
    "df_rating['user'] = le_user.fit_transform(df_rating['user'])\n",
    "df_rating['product'] = le_product.fit_transform(df_rating['product'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 120388\n",
      "Test set size: 30097\n",
      "Ratio: 0.25\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = df_rating[['user', 'product']]\n",
    "Y = df_rating['star'].astype(np.float32)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "random_state = 8\n",
    "test_size = 0.2\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=random_state)\n",
    "datasets = {'train': (X_train, Y_train), 'test': (X_test, Y_test)}\n",
    "\n",
    "print(f'Training set size: {X_train.shape[0]}')\n",
    "print(f'Test set size: {X_test.shape[0]}')\n",
    "print(f'Ratio: {X_test.shape[0] / X_train.shape[0]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique users and products\n",
    "n_users = len(df_rating[\"user\"].unique())\n",
    "n_products = len(df_rating[\"product\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Dense\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model (with additional hidden layers)\n",
    "user_input = Input(shape=(1,))\n",
    "user_embedding = Embedding(n_users, embedding_size)(user_input)\n",
    "user_flat = Flatten()(user_embedding)\n",
    "\n",
    "product_input = Input(shape=(1,))\n",
    "product_embedding = Embedding(n_products, embedding_size)(product_input)\n",
    "product_flat = Flatten()(product_embedding)\n",
    "\n",
    "dot_product = Dot(axes=1)([user_flat, product_flat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional hidden layers for depth\n",
    "hidden1 = Dense(64, activation='relu')(dot_product)\n",
    "hidden2 = Dense(32, activation='relu')(hidden1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "output = Dense(1)(hidden2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[user_input, product_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 11.1723 - val_loss: 1.9579\n",
      "Epoch 2/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.6047 - val_loss: 0.8566\n",
      "Epoch 3/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4929 - val_loss: 0.7400\n",
      "Epoch 4/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2489 - val_loss: 0.8283\n",
      "Epoch 5/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0954 - val_loss: 0.8779\n",
      "Epoch 6/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0358 - val_loss: 0.8888\n",
      "Epoch 7/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0150 - val_loss: 0.8974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18502463370>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "early_stopping = EarlyStopping(patience=4, restore_best_weights=True)\n",
    "model.fit([X_train[\"user\"], X_train[\"product\"]], Y_train[0:],\n",
    "          validation_data=([X_test[\"user\"], X_test[\"product\"]], Y_test[0:]),\n",
    "          epochs=10, batch_size=1288, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m941/941\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.7432\n",
      "Test Loss: 0.7399588227272034\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss = model.evaluate([X_test[\"user\"], X_test[\"product\"]], Y_test[0:])\n",
    "print(\"Test Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m941/941\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step\n",
      "Final MSE: 0.7400\n",
      "Final RMSE: 0.8602\n",
      "Final MAE: 0.7233\n",
      "Final R^2: 0.5715\n",
      "Precision: 0.666143673652359\n",
      "Recall: 0.7901103283264655\n",
      "Accuracy: 0.697112669036781\n",
      "F1 Score: 0.7228505411650249\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "# Predict the ratings\n",
    "y_pred = model.predict([X_test[\"user\"], X_test[\"product\"]])\n",
    "\n",
    "# Flatten the arrays\n",
    "y_true = Y_test[0:].values.flatten()\n",
    "y_pred = y_pred.flatten()\n",
    "\n",
    "# Calculate the metrics\n",
    "MSE = mean_squared_error(y_true, y_pred)\n",
    "RMSE = np.sqrt(MSE)\n",
    "MAE = mean_absolute_error(y_true, y_pred)\n",
    "R2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f'Final MSE: {MSE:.4f}')\n",
    "print(f'Final RMSE: {RMSE:.4f}')\n",
    "print(f'Final MAE: {MAE:.4f}')\n",
    "print(f'Final R^2: {R2:.4f}')\n",
    "\n",
    "# Convert the true and predicted ratings to binary labels\n",
    "threshold = 3.5\n",
    "y_true_binary = (y_true >= threshold).astype(int)\n",
    "y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "\n",
    "# Calculate precision, recall, accuracy, and F1 score\n",
    "precision = precision_score(y_true_binary, y_pred_binary)\n",
    "recall = recall_score(y_true_binary, y_pred_binary)\n",
    "accuracy = accuracy_score(y_true_binary, y_pred_binary)\n",
    "f1 = f1_score(y_true_binary, y_pred_binary)\n",
    "\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('Accuracy:', accuracy)\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = {\n",
    "    \"RMSE\": float(RMSE),\n",
    "    \"MAE\": float(MAE),\n",
    "    \"R2\": float(R2),\n",
    "    \"Precision\": float(precision),\n",
    "    \"Recall\": float(recall),\n",
    "    \"Accuracy\": float(accuracy),\n",
    "    \"F1\": float(f1)\n",
    "}\n",
    "with open('../evaluate/dmf.json', 'w') as f:\n",
    "    json.dump({\"Deep Matrix Factorization\": data}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.saving import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = '../model_state/dmf_model.h5'\n",
    "save_model(model, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "Top 8 product recommendations for user 65e5fcec011337aa452eeaf0 :\n",
      "Product ID: 65498852ae75adf790aca041\n",
      "Product ID: 65491968b87aac9ca3dabc1b\n",
      "Product ID: 65490c73b87aac9ca3dab274\n",
      "Product ID: 654917a7b87aac9ca3dab8ae\n",
      "Product ID: 6549130ab87aac9ca3dab730\n",
      "Product ID: 654a15e5ae75adf790acc15c\n",
      "Product ID: 654912d1b87aac9ca3dab71e\n",
      "Product ID: 65491a0bb87aac9ca3dabd5c\n"
     ]
    }
   ],
   "source": [
    "# Function to get recommendations for a user\n",
    "def get_recommendations(user_id, model, n_recommendations=8):\n",
    "    # Create a list of all product IDs\n",
    "    all_product_ids = np.array(list(range(n_products)))\n",
    "\n",
    "    # Repeat the user ID for all movie IDs to predict ratings for all products for this user\n",
    "    user_ids = np.array([user_id] * n_products)\n",
    "\n",
    "    # Predict ratings for all products for this user\n",
    "    predicted_ratings = model.predict([user_ids, all_product_ids])\n",
    "\n",
    "    # Sort the products based on predicted ratings in descending order\n",
    "    sorted_indices = np.argsort(predicted_ratings.flatten())[::-1]\n",
    "\n",
    "    # Get top n recommendations\n",
    "    top_n_indices = sorted_indices[:n_recommendations]\n",
    "\n",
    "    # Convert the user_id and product_ids back to original ids\n",
    "    original_user_id = le_user.inverse_transform([user_id])[0]\n",
    "    original_product_ids = le_product.inverse_transform(all_product_ids[top_n_indices])\n",
    "\n",
    "    return original_user_id, original_product_ids\n",
    "\n",
    "# Get recommendations for user with ID 100\n",
    "user_id = 100\n",
    "original_user_id, recommendations = get_recommendations(user_id, model)\n",
    "\n",
    "print(\"Top 8 product recommendations for user\", original_user_id, \":\")\n",
    "for product_id in recommendations:\n",
    "    print(\"Product ID:\", product_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for user_id in range(0, n_users-1):\n",
    "    # Get all product IDs\n",
    "    all_product_ids = df_rating['product'].unique()\n",
    "\n",
    "    # Get the product IDs that the user has already rated\n",
    "    rated_product_ids = df_rating[df_rating['user'] == user_id]['product'].unique()\n",
    "\n",
    "    # Get the product IDs that the user has not rated yet\n",
    "    unrated_product_ids = np.setdiff1d(all_product_ids, rated_product_ids)\n",
    "\n",
    "    # Create an array of the user ID repeated for the number of unrated products\n",
    "    user_ids = np.array([user_id] * len(unrated_product_ids))\n",
    "\n",
    "    # Use the model to predict the ratings for the unrated products for the given user\n",
    "    predicted_ratings = model.predict([user_ids, unrated_product_ids])\n",
    "\n",
    "    # Sort the predicted ratings in descending order and get the indices of the top ratings\n",
    "    top_ratings_indices = predicted_ratings.flatten().argsort()[-8:][::-1]\n",
    "\n",
    "    # Use these indices to get the corresponding product IDs\n",
    "    recommended_product_ids = unrated_product_ids[top_ratings_indices]\n",
    "\n",
    "    # Convert the product IDs and user ID back to their original form\n",
    "    recommended_product_ids = le_product.inverse_transform(recommended_product_ids)\n",
    "    original_user_id = le_user.inverse_transform([user_id])[0]\n",
    "\n",
    "    data = {\n",
    "        \"user_id\": original_user_id,\n",
    "        \"products\":  recommended_product_ids.tolist()\n",
    "    }\n",
    "    result.append(data)\n",
    "\n",
    "with open('model_state/dmf_predicted.json', 'w') as f:\n",
    "    json.dump({\"data\": result}, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
